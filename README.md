# NNBackPropagation
Python code to train and adjust the weight on a multilayer perceptron having two input nodes, two hidden nodes, and two output nodes. At first, the input weights were fixed, then they were generated randomly. Both sigmoid or ReLU activation functions can be used as arguments. No. of iterations are calculated based on these error values [0.01, 0.001, 0.0001, 0.00001, 0.000001]

# How to Run
- We need to pass arguments for different options with this function "RunProgram("relu","givenBias","givenWeight")"
- use keyword "sigmoid" or "relu "for difernt activation funtion
- use keyword "givenBias" or "noBias" for different Bias value
- use keyword "givenWeight" or "randomWeight" for fixed or random weight value

# What I Learned
- Back propagation algorithm
- Build back propagation algorithm with python code without using any external machine learning library.
